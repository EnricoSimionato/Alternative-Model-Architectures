{
    "path_to_storage": "/home/enricosimionato/thesis",
    "keys_for_naming": [
        "kfc_label",
        "original_model_id"
    ],

    "original_model_id": "bert-base-uncased",
    "quantization": null,
    "dtype": "float32",
    "dataset_id": "stanfordnlp/imdb",
    "max_len_samples": 16384,
    "split": [
        0.8,
        0.1,
        0.1
    ],
    "tokenizer_id": "bert-base-uncased",
    "max_len_tokenizer": 512,
    "max_epochs": 10,
    "optimizers_settings": [
        {
            "optimizer": "AdamW",
            "parameters_group": [],
            "learning_rate": 1e-05,
            "lr_scheduler": "cosine_with_warmup",
            "warmup_steps": 100,
            "monitored_metric": "loss"
        },
        {
            "optimizer": "Adam",
            "parameters_group": [],
            "learning_rate": 1e-04,
            "lr_scheduler": "cosine_with_warmup",
            "warmup_steps": 100,
            "monitored_metric": "loss"
        }
    ],
    "batch_size": 8,
    "num_workers": 2,
    "num_checks_per_epoch": 5,
    "gradient_accumulation_steps": 4,

    "num_classes": 2,
    "id2label": {
        "0": "negative",
        "1": "positive"
    },
    "label2id": {
        "negative": 0,
        "positive": 1
    },

    "original_model_parameters": 0,
    "model_parameters": 0,
    "percentage_parameters": 0,
    "model_trainable_parameters": 0,

    "adapter_method": "LoRA",
    "lora_rank": 32,
    "lora_alpha": 32,
    "target_modules": "all-linear",
    "lora_dropout": 0.05,
    "bias": "none",
    "task_type": "SEQ_CLS",

    "kfc_training": true,
    "kfc_label": "kfc",
    "initial_regularization_weight": 0.01,
    "max_regularization_weight": 1000,
    "start_step_regularization": 0,
    "steps_regularization_weight_resets": 300,

    "device": "cuda",
    "seed": 42
}