########################################    General configuration parameters    ########################################
path_to_storage: "src/experiments/results"

experiment_type: "factorization_benchmark_evaluation"

version: 11
#just_plot: True

verbose: 1
device: "cuda"
seed: 42

########################################     Model configuration parameters     ########################################
model_id: "mistralai/Mistral-7B-v0.3"
dtype: "float16"

########################################   Tokenizer configuration parameters   ########################################
tokenizer_id: "mistralai/Mistral-7B-v0.3"

########################################        Visualization parameters        ########################################
figure_size: [5, 10]

########################################     Layers factorization parameters    ########################################
factorization_methods:
    - "LocalSVD"
#    - "Hadamard"
    - "GlobalBase"

target_layers:
    q_proj:
        rank: 2048
#        learning_rate: 0.01
#        max_iterations: 1000
    k_proj:
        rank: 64
#        learning_rate: 0.01
#        max_iterations: 1000
    v_proj:
        rank: 64
#        learning_rate: 0.01
#        max_iterations: 1000

########################################          Benchmarks parameters         ########################################
benchmark_ids:
    - "hellaswag"
#    - "truthfulqa_mc1"
#    - "arc_challenge"
evaluation_args:
    truthfulqa_mc1:
        batch_size: 32
    arc_challenge:
        batch_size: 32
    hellaswag:
        batch_size: 32
