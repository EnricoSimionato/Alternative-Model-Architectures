{
    "path_to_storage": "/Users/enricosimionato/Desktop/Alternative-Model-Architectures/src/experiments/performed_experiments",
    "keys_for_naming": [
        "factorization_method",
        "original_model_id"
    ],

    "original_model_id": "bert-base-uncased",
    "quantization": null,
    "dtype": "float16",

    "dataset_id": "timdettmers/openassistant-guanaco",
    "max_len_samples": 16384,
    "split": [
        0.8,
        0.1,
        0.1
    ],
    "tokenizer_id": "bert-base-uncased",
    "tokenizer_id_for_chat_template": "meta-llama/Llama-2-70b-chat-hf",
    "stop_tokens": [
        "[INST]",
        "[SEP]"
    ],
    "max_len_tokenizer": 512,
    "max_epochs": 1,
        "optimizers_settings": [
        {
            "optimizer": "AdamW",
            "parameters_group": [],
            "learning_rate": 1e-05,
            "lr_scheduler": "cosine_with_warmup",
            "warmup_steps": 100,
            "monitored_metric": "loss"
        }
    ],
    "batch_size": 8,
    "num_workers": 1,
    "num_checks_per_epoch": 5,
    "gradient_accumulation_steps": 4,

    "factorization_method": "LocalSVD",
    "regularized_training": true,
    "target_layers": {
        "query": {
            "rank": 256
        },
        "key": {
            "rank": 256
        },
        "value": {
            "rank": 256
        },
        "dense": {
            "rank": 256
        }
    },
    "verbose": 1,

    "original_model_parameters": 0,
    "model_parameters": 0,
    "percentage_parameters": 0,
    "model_trainable_parameters": 0,

    "device": "mps",
    "seed": 42
}
